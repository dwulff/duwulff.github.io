require(wordnet)
initDict()
WNHOME
?initDict
get('WNHOME')
initDict('/Users/wulff/Downloads/dict')
require(wordnet)
getSynonyms('house')
filter <- getTermFilter("ExactMatchFilter", "company", TRUE)
?getTermFilter
getTermFilter("ExactMatchFilter", "company", TRUE)
filter <- getTermFilter("ExactMatchFilter", "company", TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getDict()
?getDict
setDict('~/Downloads/dict/')
setDict('~/Downloads/')
WNHOME = '~/Downloads/'
getDict()
setDict('~/Downloads/')
require(wordnet)
initDict
initDict()
WNHOME
WNHOME = "~/Downloads/dict/"
initDict()
initDict("~/Downloads/dict/")
WNHOME = "~/Downloads/dict"
initDict()
initDict("~/Downloads/dict")
initDict("/Users/wulff/Downloads/dict")
WNHOME = "/Users/wulff/Downloads/dict"
initDict()
getDict()
WNHOME = "/Users/wulff/Downloads/"
getDict()
getDict("/Users/wulff/Downloads/)
getDict("/Users/wulff/Downloads/")
?getDict
getDict()
WNHOME
initDict
?initDict
initDict('"/Users/wulff/Downloads/"')
initDict('/Users/wulff/Downloads/')
initDict('/Users/wulff/Downloads/dict/')
WNHOME = '/Users/wulff/Downloads/dict/'
getDict()
?setDict
setDict('/Users/wulff/Downloads/dict/')
getDict
getDict()
filter <- getTermFilter("ExactMatchFilter", "company", TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
terms
getSynonyms(terms[[1]])
filter <- getTermFilter("ExactMatchFilter", "house", TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getSynonyms(terms[[1]])
getsyn = function(word){
filter <- getTermFilter("ExactMatchFilter", "house", TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getSynonyms(terms[[1]])
}
getsyn('house')
iq = 1
q = comp[iq]
options(stringsAsFactors = F)
require(googlesheets)
require(devtools);install_github('dwulff/translatoR');require(translatoR)
setwd('~/Dropbox (2.0)/Work/Software/dwulff.github.io/')
goodchoices = read.table('_Goodchoices/GoodchoicesSurveys.txt',header=F,sep='\n')[,1]
networks    = read.table('_Networks/NetworksSurveys.txt',header=F,sep='\n')[,1]
tab = paste0(networks[1],' (Antworten)')
gs = gs_title(tab)
d = gs_read(gs)
d = as.data.frame(d)
names = d[,3]
comp = unlist(d[,4:10])
crit = unlist(d[,11:13])
comp.processed = gsub('1.\t','',comp)
crit.processed = gsub('1.\t','',crit)
comp.processed = sapply(comp.processed,translatoR,'en','de')
q = comp[iq]
q
stops1 = read.table('~/Desktop/EnglishStopWord1.txt')
stops1
stops1[1]
class(stops1)
dim(stops1)
stops1 = read.table('~/Desktop/EnglishStopWord1.txt')[,1]
stops1
stops1 = read.table('~/Desktop/EnglishStopWord1.txt',sep='\n')[,1]
stops1
stops1 = read.table('~/Desktop/EnglishStopWord1.txt',sep='\n\n')[,1]
sapply(stops,strsplit,'\n')
sapply(stops1,strsplit,'\n')
stops1 = unlist(sapply(stops1,strsplit,'\n'))
stops1 = read.table('~/Desktop/EnglishStopWord2.txt',sep='\t')
stops2 = read.table('~/Desktop/EnglishStopWord2.txt')
con = file('~/Desktop/EnglishStopWord2.txt')
stops2 = readLines(con)
stops2
stops2 = unlist(sapply(stops2,strsplit,'\n'))
stops2
con = file('~/Desktop/EnglishStopWord2.txt')
stops2 = readLines(con)
stops2 = readLines(con);close(con)
con = file('~/Desktop/EnglishStopWord2.txt')
stops2 = readLines(con);close(con)
close(con)
close(con)
stops2 = unlist(sapply(stops2,strsplit,'\t'))
stops2
stops1 = read.table('~/Desktop/GermanStopWord1.txt',sep='\n')
stops1
stops1 = read.table('~/Desktop/GermanStopWord1.txt',sep='\t')
stops1
stops1 = read.table('~/Desktop/GermanStopWord1.txt',sep='\t')[,1]
stops1 = read.table('~/Desktop/GermanStopWord1.txt',sep='\t')[,2]
stops1
stops4 = read.table('~/Desktop/GermanStopWord2.txt',sep='\t')
stops4
stops = c(stops1,stops2,stops3,stops4)
stops1 = read.table('~/Desktop/EnglishStopWord1.txt',sep='\n')[,1]
stops1 = unlist(sapply(stops1,strsplit,'\n'))
con = file('~/Desktop/EnglishStopWord2.txt')
stops2 = readLines(con);close(con)
stops2 = unlist(sapply(stops2,strsplit,'\t'))
stops3 = read.table('~/Desktop/GermanStopWord1.txt',sep='\t')[,2]
stops4 = read.table('~/Desktop/GermanStopWord2.txt',sep='\t')[,1]
stops = c(stops1,stops2,stops3,stops4)
q = comp[iq]
q
q = comp[iq]
gsub(stops,'',q)
length(stops)
q = comp[iq]
for(stop in stops) q = gsub(stop,'',q)
q
stops = c(stops1,stops2,stops3,stops4)
stops = paste0(' ',stops,' ')
stops
q = comp[iq]
for(stop in stops) q = gsub(stop,'',q)
q
q = comp[iq]
q
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q
q = strsplit(q,' ')
q
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')
q = q[!q %in% stops]
q
stops = c(stops1,stops2,stops3,stops4)
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')
q = q[!q %in% stops]
q
'das'%in%stops
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')
q %in% stops
q
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
q
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q
getsyn = function(word){
filter <- getTermFilter("ExactMatchFilter", "house", TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getSynonyms(terms[[1]])
}
lapply(q,getsyn)
getsyn = function(word){
filter <- getTermFilter("ExactMatchFilter", word, TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getSynonyms(terms[[1]])
}
lapply(q,getsyn)
q
q = sapply(q,translatoR,'de','en')
q = tolower(q)
q
getsyn("barabasi")
word = "barabasi"
filter <- getTermFilter("ExactMatchFilter", word, TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
getSynonyms(terms[[1]])
terms
getsyn = function(word){
filter <- getTermFilter("ExactMatchFilter", word, TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
if(!is.null(terms)) getSynonyms(terms[[1]])
}
lapply(q,getsyn)
sapply(q,getsyn)
lapply(q,getsyn)
unlist(lapply(q,getsyn))
q = c(q,unlist(lapply(q,getsyn)))
q
iq = 20
q = comp[iq]
q
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
q
q = c(q,unlist(lapply(q,getsyn)))
q
q = paste(q,collapse=' ')
comp.processed = c()
for(iq in 1:comp){
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[i] = q
}
iq = 1
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[iq] = q
comp.processed = c()
for(iq in 1:comp){
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[iq] = q
}
print(i)
comp.processed = c()
for(iq in 1:comp){
print(iq)
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[iq] = q
}
comp.processed = c()
for(iq in 1:length(comp)){
print(iq)
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[iq] = q
}
comp.processed
comp.processed = c()
for(iq in 1:length(comp)){
print(iq)
# process
q = comp[iq]
q = gsub('[[:punct:]]','',q)
q = gsub('[[:digit:]]','',q)
q = tolower(q)
q = strsplit(q,' ')[[1]]
q = q[!q %in% stops]
# translate
q = sapply(q,translatoR,'de','en')
q = tolower(q)
# get syns
q = c(q,unlist(lapply(q,getsyn)))
# bind
q = paste(q,collapse=' ')
# store
comp.processed[iq] = q
}
comp
comp.processed
texts = comp.processed
corpus   = tm:::Corpus(VectorSource(texts))
corpus   = tm:::tm_map(corpus, content_transformer(tolower))
corpus   = tm:::tm_map(corpus, tm:::removePunctuation)
corpus   = tm:::Corpus(VectorSource(texts))
require(tm)
corpus   = tm:::Corpus(VectorSource(texts))
corpus   = tm:::tm_map(corpus, content_transformer(tolower))
corpus   = tm:::tm_map(corpus, tm:::removePunctuation)
corpus   = tm:::tm_map(corpus, function(x) tm:::removeWords(x, tm:::stopwords(language)))
corpus   = tm:::tm_map(corpus, tm:::stemDocument, language = language)
language = 'English'
corpus   = tm:::Corpus(VectorSource(texts))
corpus   = tm:::tm_map(corpus, content_transformer(tolower))
corpus   = tm:::tm_map(corpus, tm:::removePunctuation)
corpus   = tm:::tm_map(corpus, function(x) tm:::removeWords(x, tm:::stopwords(language)))
corpus   = tm:::tm_map(corpus, tm:::stemDocument, language = language)
language
?stemDocument
corpus   = tm:::Corpus(VectorSource(texts))
corpus   = tm:::tm_map(corpus, content_transformer(tolower))
corpus   = tm:::tm_map(corpus, tm:::removePunctuation)
corpus   = tm:::tm_map(corpus, function(x) tm:::removeWords(x, tm:::stopwords(language)))
corpus   = tm:::tm_map(corpus, tm:::stemDocument, language = language)
corpus   = tm:::Corpus(VectorSource(texts))
corpus   = tm:::tm_map(corpus, content_transformer(tolower))
corpus   = tm:::tm_map(corpus, tm:::removePunctuation)
corpus   = tm:::tm_map(corpus, function(x) tm:::removeWords(x, tm:::stopwords(language)))
corpus
corpus   = tm:::Corpus(VectorSource(texts))
mat = TermDocumentMatrix(corpus)
td.mat = as.matrix(TermDocumentMatrix(corpus))
td.mat.lsa = lw_bintf(td.mat) * gw_idf(td.mat)
require(lsa)
td.mat = as.matrix(TermDocumentMatrix(corpus))
td.mat.lsa = lw_bintf(td.mat) * gw_idf(td.mat)
lsaSpace = lsa(td.mat.lsa)
dist.mat.lsa = 1/(dist(t(as.textmatrix(lsaSpace))) + .1)
a = graph_from_adjacency_matrix(dist.mat.lsa,'undirected')
require(igraph)
a = graph_from_adjacency_matrix(dist.mat.lsa,'undirected')
cl = cluster_louvain(a)
ls(cl)
table(cl$memberships)
a = hclust(dist(t(as.textmatrix(lsaSpace))),method = 'ward.D')
table(cutree(a,20))
table(cutree(a,10))
table(cutree(a,5))
texts
table(cutree(a,5))
cl = cluster_optimal(a)
a = graph_from_adjacency_matrix(dist.mat.lsa,'undirected')
cl = cluster_optimal(a)
table(cl$memberships)
cl
ls(cl)
table(cl$membership)
cl$membership
cl = cluster_walktrap(a)
table(cl$membership)
cl = cluster_edge_betweenness(a)
table(cl$membership)
a = hclust(dist(t(as.textmatrix(lsaSpace))),method = 'ward.D')
table(cutree(a,5))
table(cutree(a,3))
comp[cutree(a,3) == 1]
cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1))
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=100)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=200)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=200)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=200)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=500)
hist(cmdscale(dist(t(as.textmatrix(lsaSpace))),k = 1),breaks=500,xlim=c(-10,10))
options(stringsAsFactors = F)
require(googlesheets)
require(devtools);install_github('dwulff/translatoR');require(translatoR)
setwd('~/Dropbox (2.0)/Work/Software/dwulff.github.io/')
getsyn = function(word){
filter <- getTermFilter("ExactMatchFilter", word, TRUE)
terms <- getIndexTerms("NOUN", 1, filter)
if(!is.null(terms)) getSynonyms(terms[[1]])
}
goodchoices = read.table('_Goodchoices/GoodchoicesSurveys.txt',header=F,sep='\n')[,1]
networks    = read.table('_Networks/NetworksSurveys.txt',header=F,sep='\n')[,1]
tab = paste0(networks[1],' (Antworten)')
gs = gs_title(tab)
d = gs_read(gs)
d = as.data.frame(d)
names = d[,3]
d
names
networks
tab = paste0(networks[1],' (Antworten)')
gs = gs_title(tab)
d = gs_read(gs)
d = as.data.frame(d)
# networks
# networks
names = d[,3]
names = d[,3]
comp = unlist(d[,4:10])
crit = unlist(d[,11:13])
cat(comp,'\n')
sapply(comp,cat,sep='\n')
sapply(comp,function(x) cat(x,'\n'))
sapply(comp,function(x) cat(x,'\n\n'))
for(com in comp) cat(co,'\n\n'))
for(com in comp) cat(co,'\n\n')
for(com in comp) cat(com,'\n\n')
log(20)
for(crit in comp) cat(com,'\n\n')
for(cri in crit) cat(cri,'\n\n')
for(cri in crit) cat(cri,'\n\n')
crit = unlist(d[,11:13])
for(cri in crit) cat(cri,'\n\n')
